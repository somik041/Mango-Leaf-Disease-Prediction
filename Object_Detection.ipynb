{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNoF9NVT0N6rO7fPMriIrfk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/somik041/Mango-Leaf-Disease-Prediction/blob/main/Object_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#                        Object Detection[Classification + Localization]"
      ],
      "metadata": {
        "id": "8kjfuSHLib7Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1: Importing Libraries"
      ],
      "metadata": {
        "id": "qkmD_8wQTMGD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "EFngTXln6keI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL.Image, PIL.ImageFont, PIL.ImageDraw\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds"
      ],
      "metadata": {
        "id": "Kh3qTMVm_1Xp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2: Visualization Utilities"
      ],
      "metadata": {
        "id": "LyPH6hYQTvGg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "im_width = 75\n",
        "im_height =75\n",
        "use_normalized_coordinates = True"
      ],
      "metadata": {
        "id": "zeFKQAsQTIDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_bounding_boxes_on_image_array(image, boxes, color=[], thickness=1, display_str_list=()):\n",
        "    image_pil = PIL.Image.fromarray(image)\n",
        "    rgbimg = PIL.Image.new(\"RGBA\", image_pil.size)\n",
        "    rgbimg.paste(image_pil)\n",
        "    draw_bounding_boxes_on_image(rgbimg, boxes, color, thickness, display_str_list)\n",
        "    return np.array(rgbimg)\n",
        "\n",
        "def draw_bounding_boxes_on_image(image, boxes, color=[], thickness=1, display_str_list=()):\n",
        "    boxes_shape=boxes.shape\n",
        "    if not boxes_shape:\n",
        "        return\n",
        "    if len(boxes_shape) !=2 or boxes_shape[1] !=4:\n",
        "        raise ValueError('Input must be of size [N, 4]')\n",
        "    for i in range(boxes_shape[0]):\n",
        "        draw_bounding_box_on_image(image, boxes[i,1], boxes[i,0], boxes[i,3], boxes[i,2], color[i],\n",
        "                                   thickness, display_str_list[i])\n",
        "\n",
        "def draw_bounding_box_on_image(image, ymin, xmin, ymax, xmax,\n",
        "                               color='red', thickness=1, display_str_list=None, use_normalized_coordinates=True):\n",
        "    draw = PIL.ImageDraw.Draw(image)\n",
        "    im_width, im_height = image.size\n",
        "    if use_normalized_coordinates:\n",
        "        (left, right, top, bottom) = (xmin*im_width, xmax*im_width,\n",
        "                                      ymin*im_height, ymax*im_height)\n",
        "    else:\n",
        "        (left, right, top, bottom) = (xmin, xmax, ymin, ymax)\n",
        "\n",
        "    draw.line([(left, top), (left, bottom), (right, bottom),\n",
        "               (right, top), (left, top)], width=thickness, fill=color)"
      ],
      "metadata": {
        "id": "Tw0CMBrKVJla"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dataset_to_numpy_util(training_dataset, validation_dataset, N):\n",
        "    batch_train_ds = training_dataset.unbatch().batch(N)\n",
        "\n",
        "    if tf.executing_eagerly():\n",
        "        for validation_digits, validation_targets in validation_dataset:\n",
        "            validation_digits = validation_digits.numpy()\n",
        "            validation_labels = validation_targets[0].numpy()\n",
        "            validation_bboxes = validation_targets[1].numpy()\n",
        "            break\n",
        "        for training_digits, training_targets in training_dataset:\n",
        "            training_digits = training_digits.numpy()\n",
        "            training_labels = training_targets[0].numpy()\n",
        "            training_bboxes = training_targets[1].numpy()\n",
        "            break\n",
        "    validation_labels = np.argmax(validation_labels, axis=-1)\n",
        "    training_labels = np.argmax(training_labels, axis=-1)\n",
        "    return (training_digits, training_labels, training_bboxes, validation_digits, validation_labels, validation_bboxes)"
      ],
      "metadata": {
        "id": "uulgPfywVJ-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MATPLOTLIB_FONT_DIR = os.path.join(os.path.dirname(plt.__file__), \"mpl-data/fonts/ttf\")\n",
        "def create_digits_from_local_fonts(n):\n",
        "    font_labels = []\n",
        "    img = PIL.Image.new('LA', (im_width, im_height), color = (0,255)) # fully visible\n",
        "    font1 = PIL.ImageFont.truetype(os.path.join(MATPLOTLIB_FONT_DIR, 'DejaVuSansMono-Oblique.ttf'), 25)\n",
        "    font2 = PIL.ImageFont.truetype(os.path.join(MATPLOTLIB_FONT_DIR, 'STIXGeneral.ttf'), 25)\n",
        "    d = PIL.ImageDraw.Draw(img)\n",
        "    for i in range(n):\n",
        "        font_labels.append(i % 10)\n",
        "        d.text((7+i*75, 0 if i<10 else -4), str(i) % 10, fill=(255,255), font=font1 if i<10 else font2)\n",
        "    font_digits = np.array(img.getdata(), np.float32)[:,0] / 255.0 # black is 0, white is 1\n",
        "    font_digits = np.reshape(np.stack(np.split(np.reshape(font_digits, [75, 75*n]), n, axis=1), axis=1), [n, 75*75])\n",
        "    return font_digits, font_labels"
      ],
      "metadata": {
        "id": "QMg4yxc7VKKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_digits_with_boxes(digits, predictions, labels, pred_bboxes, bboxes, iou, title):\n",
        "    n = 10\n",
        "\n",
        "\n",
        "    predictions = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 0])\n",
        "    labels = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 0])\n",
        "    indexes = np.random.choice(len(predictions), size=n)\n",
        "    n_digits = digits[indexes]\n",
        "    n_predictions = predictions[indexes]\n",
        "    n_labels = labels[indexes]\n",
        "\n",
        "    n_iou = []\n",
        "    if len(iou) > 0:\n",
        "        n_iou = iou[indexes]\n",
        "\n",
        "    n_pred_bboxes = []\n",
        "    if len(pred_bboxes) > 0:\n",
        "        n_pred_bboxes = pred_bboxes[indexes]\n",
        "\n",
        "    n_bboxes = []\n",
        "    if len(bboxes) > 0:\n",
        "        n_bboxes = bboxes[indexes]\n",
        "\n",
        "\n",
        "    n_digits = n_digits*255.0\n",
        "    n_digits = np.reshape(n_digits, [n, 75, 75])\n",
        "    fig=plt.figure(figsize=(20, 4))\n",
        "    plt.title(title)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "\n",
        "    for i in range(10):\n",
        "        ax = fig.add_subplot(1, 10, i+1)\n",
        "        bboxes_to_plot = []\n",
        "        colors_to_plot = []\n",
        "        if len(n_pred_bboxes) > i and len(n_pred_bboxes[i]) > 0:\n",
        "            bboxes_to_plot.append(n_pred_bboxes[i])\n",
        "            colors_to_plot.append('red')\n",
        "\n",
        "        if len(n_bboxes) > i and len(n_bboxes[i]) > 0:\n",
        "            bboxes_to_plot.append(n_bboxes[i])\n",
        "            colors_to_plot.append('green')\n",
        "\n",
        "\n",
        "        img_to_draw = draw_bounding_boxes_on_image_array(image=n_digits[i],\n",
        "                                                         boxes=np.array(bboxes_to_plot),\n",
        "                                                         color=['red', 'green'],\n",
        "                                                         display_str_list=[\"True\", \"Pred\"])\n",
        "        plt.xlabel(n_predictions[i])\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "\n",
        "        if n_predictions[i] != n_labels[i]:\n",
        "            ax.xaxis.label.set_color('red')\n",
        "\n",
        "        plt.imshow(img_to_draw)\n",
        "\n",
        "        if len(n_iou) > i:\n",
        "            color = \"black\"\n",
        "            if (n_iou[i][0] < iou_threshold):\n",
        "                color = \"red\"\n",
        "            ax.text(0.2, -0.3, \"IoU: \" + str(round(n_iou[i][0], 3)), color=color, transform=ax.transAxes)"
      ],
      "metadata": {
        "id": "7pf-1U77VKNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_metrics(metric_name, title):\n",
        "    plt.title(title)\n",
        "    plt.plot(history.history[metric_name],color='blue',label=metric_name)\n",
        "    plt.plot(history.history['val_'+metric_name],color='green',label='val_'+metric_name)"
      ],
      "metadata": {
        "id": "4D15buG00g34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3: Loading and Preprocessing the Dataset"
      ],
      "metadata": {
        "id": "c5_DZfwYiJE3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "strategy = tf.distribute.get_strategy()\n",
        "strategy.num_replicas_in_sync"
      ],
      "metadata": {
        "id": "TqD_e_e_2uyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCHSIZE = 64*strategy.num_replicas_in_sync"
      ],
      "metadata": {
        "id": "puTqX0nL7oN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_image_tfds(image, label):\n",
        "  xmin = tf.random.uniform([], 0, 48, dtype=tf.int32)\n",
        "  ymin = tf.random.uniform([], 0, 48, dtype=tf.int32)\n",
        "  image = tf.reshape(image, [28, 28, 1])\n",
        "  image = tf.image.pad_to_bounding_box(image, ymin, xmin, 75, 75)\n",
        "  image = tf.cast(image, tf.float32)\n",
        "  xmin = tf.cast(xmin, tf.float32)\n",
        "  ymin = tf.cast(ymin, tf.float32)\n",
        "\n",
        "  xmax = (xmin + 28)/75\n",
        "  ymax = (ymin + 28)/75\n",
        "  xmin = xmin/75\n",
        "  ymin = ymin/75\n",
        "  # Return image, and a tuple containing label and bounding box coordinates\n",
        "  return image, (label, [xmin, ymin, xmax, ymax])"
      ],
      "metadata": {
        "id": "NcGwitUsVKQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_training_dataset():\n",
        "  with strategy.scope():\n",
        "    dataset = tfds.load(\"mnist\", split=\"train\", as_supervised=True, try_gcs=True)\n",
        "    dataset = dataset.map(read_image_tfds, num_parallel_calls=16)\n",
        "    dataset = dataset.shuffle(5000, reshuffle_each_iteration=True)\n",
        "    dataset = dataset.repeat()\n",
        "    dataset = dataset.batch(BATCHSIZE, drop_remainder=True)\n",
        "    dataset = dataset.prefetch(-1)\n",
        "  return dataset\n",
        "\n",
        "def get_validation_dataset():\n",
        "  with strategy.scope():\n",
        "    dataset = tfds.load(\"mnist\", split=\"train\", as_supervised=True, try_gcs=True)\n",
        "    dataset = dataset.map(read_image_tfds, num_parallel_calls=16)\n",
        "    dataset = dataset.batch(10000, drop_remainder=True)\n",
        "    dataset = dataset.repeat()\n",
        "  return dataset"
      ],
      "metadata": {
        "id": "98kotlX-VKS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "  training_dataset = get_training_dataset()\n",
        "  validation_dataset = get_validation_dataset()"
      ],
      "metadata": {
        "id": "DnkMOKNaVKV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(training_digits, training_labels, training_bboxes, validation_digits, validation_labels, validation_bboxes) = dataset_to_numpy_util(training_dataset, validation_dataset, 10)"
      ],
      "metadata": {
        "id": "Fkz6MAERVKZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize Data"
      ],
      "metadata": {
        "id": "HPLq6ndbHgGQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display_digits_with_boxes(training_digits, training_labels, training_labels, np.array([]), training_bboxes, np.array([]), \"Training Digits & Labels\")"
      ],
      "metadata": {
        "id": "rCGv1iY2IIfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2885b324"
      },
      "source": [
        "display_digits_with_boxes(validation_digits, validation_labels, validation_labels, np.array([]), validation_bboxes, np.array([]), \"Validation Digits & Labels\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4: Define The Network"
      ],
      "metadata": {
        "id": "cJlBX_ciDswl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_extractor(inputs):\n",
        "    x = tf.keras.layers.Conv2D(16, activation='relu', kernel_size=3, input_shape=(75, 75, 1))(inputs)\n",
        "    x = tf.keras.layers.AveragePooling2D((2, 2))(x)\n",
        "\n",
        "    x = tf.keras.layers.Conv2D(32, activation='relu', kernel_size=3)(x)\n",
        "    x = tf.keras.layers.AveragePooling2D((2, 2))(x)\n",
        "\n",
        "    x = tf.keras.layers.Conv2D(64, activation='relu', kernel_size=3)(x)\n",
        "    x = tf.keras.layers.AveragePooling2D((2, 2))(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "7BobdCOgDILf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dense_layers(inputs):\n",
        "    x = tf.keras.layers.Flatten()(inputs)\n",
        "    x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "e42mF1WpEVY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classifier(inputs):\n",
        "    classification_output = tf.keras.layers.Dense(10, activation='softmax', name=\"classification\")(inputs)\n",
        "    return classification_output"
      ],
      "metadata": {
        "id": "Kma_C6L4EVVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bounding_box_regression(inputs):\n",
        "    bounding_box_regression_output = tf.keras.layers.Dense(4, name=\"bounding_box\")(inputs)\n",
        "    return bounding_box_regression_output"
      ],
      "metadata": {
        "id": "tDnXzOgbEVTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def final_model(inputs):\n",
        "    feature_cnn = feature_extractor(inputs)\n",
        "    dense_output = dense_layers(feature_cnn)\n",
        "    classification_output = classifier(dense_output)\n",
        "    bounding_box_output = bounding_box_regression(dense_output)\n",
        "\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=[classification_output, bounding_box_output])\n",
        "    return model"
      ],
      "metadata": {
        "id": "q_LS1SUXEVQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def define_and_compile_model(inputs):\n",
        "    model = final_model(inputs)\n",
        "\n",
        "    model.compile(optimizer = 'adam', loss = {'classification': 'sparse_categorical_crossentropy', 'bounding_box': 'mse'},\n",
        "                  metrics = {'classification': 'accuracy', 'bounding_box': 'mse'})\n",
        "    return model"
      ],
      "metadata": {
        "id": "8BFHY1lvEVOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "    inputs = tf.keras.layers.Input(shape=(75, 75, 1))\n",
        "    model = define_and_compile_model(inputs)\n",
        "    model.summary()"
      ],
      "metadata": {
        "id": "fyoQdrsnEVLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5: Train and Validate the Model"
      ],
      "metadata": {
        "id": "5gKzMaS5KluH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 5\n",
        "steps_per_epoch = 60000//BATCHSIZE\n",
        "\n",
        "\n",
        "history = model.fit(training_dataset, steps_per_epoch=steps_per_epoch,\n",
        "                    epochs=EPOCHS, validation_data=validation_dataset, validation_steps=1)\n",
        "\n",
        "loss, classification_loss, bounding_box_loss, classification_acc, bounding_box_mse = model.evaluate(validation_dataset, steps=1)\n",
        "print(\"\\n------------------------------------\\n\")\n",
        "print(\"Validation accuracy: \", classification_acc)\n",
        "print(\"\\n------------------------------------\\n\")"
      ],
      "metadata": {
        "id": "MZ6HhbldEVIP"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_metrics(\"bounding_box_mse\", \"Bounding Box MSE\")"
      ],
      "metadata": {
        "id": "h8ePVpAYEVFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_metrics(\"classification_accuracy\", \"Classification Accuracy\")"
      ],
      "metadata": {
        "id": "vibNg4gMEU8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_metrics(\"classification_loss\", \"Classification Loss\")"
      ],
      "metadata": {
        "id": "t16EeEssEUvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def intersection_over_union(pred_box, true_box):\n",
        "    xmin_pred, ymin_pred, xmax_pred, ymax_pred = np.split(pred_box, 4, axis=1)\n",
        "    xmin_true, ymin_true, xmax_true, ymax_true = np.split(true_box, 4, axis=1)\n",
        "\n",
        "    smoothing_factor = 1e-10\n",
        "\n",
        "    xmin_overlap = np.maximum(xmin_pred, xmin_true)\n",
        "    xmax_overlap = np.minimum(xmax_pred, xmax_true)\n",
        "    ymin_overlap = np.maximum(ymin_pred, ymin_true)\n",
        "    ymax_overlap = np.minimum(ymax_pred, ymax_true)\n",
        "\n",
        "    pred_box_area = (xmax_pred - xmin_pred) * (ymax_pred - ymin_pred)\n",
        "    true_box_area = (xmax_true - xmin_true) * (ymax_true - ymin_true)\n",
        "\n",
        "    overlap_area = np.maximum(xmax_overlap - xmin_overlap, 0) * np.maximum(ymax_overlap - ymin_overlap, 0)\n",
        "    union_area = (pred_box_area + true_box_area) - overlap_area\n",
        "\n",
        "    iou = overlap_area / (union_area + smoothing_factor)\n",
        "    return iou"
      ],
      "metadata": {
        "id": "FU_Z-hAREUfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = model.predict(validation_digits, batch_size = 64)\n",
        "\n",
        "prediction_labels = np.argmax(prediction[0], axis=1)\n",
        "prediction_bboxes = prediction[1]"
      ],
      "metadata": {
        "id": "_QdNOScLQLWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iou = intersection_over_union(prediction_bboxes, validation_bboxes)\n",
        "\n",
        "iou_threshold = 0.6\n",
        "\n",
        "display_digits_with_boxes(validation_digits, prediction_labels, validation_labels,\n",
        "                          prediction_bboxes, validation_bboxes, iou, \"True and Pred values\")"
      ],
      "metadata": {
        "id": "NMY1ntdKQqD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ExukgCmcZxzv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}